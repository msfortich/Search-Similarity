{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb4ce4d-1752-48b4-b793-0133c7ff2b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f165b6c-3295-4b57-a5b2-2487dd259bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e08111c-050f-4917-8ceb-3c01e67c4de2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 22:40:07.826378: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 22:40:09.132748: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-07-18 22:40:09.132902: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-07-18 22:40:09.132914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from google.cloud import bigquery\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59cdb0-8d5c-49c2-88f7-9d4e96f66ee3",
   "metadata": {},
   "source": [
    "function to query and process the data and cosine similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1192d520-0e5a-4c26-a59f-0f9f7a9616eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_and_get_data(start_date):\n",
    "    client = bigquery.Client(location=\"US\")\n",
    "\n",
    "    # query to get the search terms from the trends final report\n",
    "    query = \"\"\"\n",
    "    SELECT search_term, kids, ya, adult, fiction, nonfiction, religious, christian, unknown, lemmatized_search_term, pct_rank\n",
    "    FROM hc-data-prod-analytics.ds_prod.ds_trends_final_report\n",
    "    WHERE title_care=False\n",
    "    AND nonfiction = False\n",
    "    AND fiction = True\n",
    "    AND language = 'english'\n",
    "    AND start_date >= '{}';\n",
    "    \"\"\".format(start_date)\n",
    "    \n",
    "    df = client.query(query, location=\"US\").to_dataframe()\n",
    "    terms = list(df['search_term'].unique())\n",
    "    \n",
    "    # query pulls the products associated to the search terms we pulled from the previous query\n",
    "    def chunks(l, n):\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i + n]\n",
    "\n",
    "    products = []\n",
    "    for chunk in chunks(terms, 3000):\n",
    "        chunk = '(\"' + '\",\"'.join(chunk) + '\")'\n",
    "        q = \"\"\"\n",
    "        SELECT clickeditemname, searchterm \n",
    "        FROM `hc-data-prod-analytics.datascience.amazon_weekly_search_term_full`\n",
    "        WHERE searchterm IN {}\n",
    "        \"\"\".format(chunk)\n",
    "        products.append(client.query(q, location=\"US\").to_dataframe())\n",
    "    \n",
    "    products = pd.concat(products)\n",
    "    products = products.groupby(['searchterm'])['clickeditemname'].apply(list)\n",
    "    products = pd.DataFrame(products)\n",
    "    df = pd.merge(df, products, how='left', left_on='search_term', right_on=products.index)\n",
    "    \n",
    "    df = df.reset_index().sort_values(['search_term']).dropna()\n",
    "    \n",
    "    # generate embeddings for unique search terms\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(df['search_term'].unique().tolist())\n",
    "    embed_df = pd.DataFrame(embeddings, index=df['search_term'].unique())\n",
    "    \n",
    "    # transforming the clicked items into a binary matrix\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    mlb_array = mlb.fit_transform(df['clickeditemname'])\n",
    "    mlb_array = pd.DataFrame.sparse.from_spmatrix(mlb_array)\n",
    "    mlb_array['search_term'] = df['search_term'].values\n",
    "    mlb_array.drop_duplicates(subset=['search_term'], inplace=True)\n",
    "    mlb_array.index = mlb_array['search_term'].values\n",
    "    mlb_array.drop('search_term', axis=1, inplace=True)\n",
    "    \n",
    "    # merging search term embeddings and clicked items\n",
    "    sim_df = embed_df.merge(mlb_array, left_on=embed_df.index, right_on=mlb_array.index)\n",
    "    sim_df.index = sim_df.iloc[:, 0].values\n",
    "    sim_df.drop(['key_0'], axis=1, inplace=True)\n",
    "    \n",
    "    # calculating cosine similarity scores\n",
    "    sim2 = cosine_similarity(sim_df)\n",
    "    sims_df = pd.DataFrame(sim2, index=embed_df.index, columns=embed_df.index)\n",
    "    sims_df.index.name = None\n",
    "    new_sims_df = sims_df.reset_index().rename(columns={'index': 'Search Term'})\n",
    "    melt = new_sims_df.melt(id_vars=[\"Search Term\"], var_name=\"Compared Term\", value_name=\"Similarity Score\")\n",
    "    \n",
    "    # querying the mapped search terms and trends\n",
    "    query_trends = \"\"\"\n",
    "    SELECT * FROM `hc-data-prod-analytics.oss.bi_dashboard_trends_living_searchterms`\n",
    "    \"\"\"\n",
    "    df_trends = client.query(query_trends, location=\"US\").to_dataframe()\n",
    "    \n",
    "    return melt, df_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0e2ea-f4ae-481d-9528-6113e6e59818",
   "metadata": {},
   "source": [
    "function groups by trend and processess the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64245005-a16d-48ea-bde1-a0537cd2f297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_trend_data(melt, df_trends, trend, quantile=0.99):\n",
    "    def dynamic_threshold(df, quantile=0.99):\n",
    "        thresholds = df.groupby('Search Term')['Similarity Score'].quantile(quantile)\n",
    "        return thresholds\n",
    "    \n",
    "    thresholds = dynamic_threshold(melt, quantile=quantile)\n",
    "    \n",
    "    filtered = melt.join(thresholds, on='Search Term', rsuffix='_threshold')\n",
    "    filtered = filtered[filtered['Similarity Score'] >= filtered['Similarity Score_threshold']].drop('Similarity Score_threshold', axis=1)\n",
    "    \n",
    "    # merge cosine sim matrix with trends table\n",
    "    filtered_with_trends = filtered.merge(df_trends, left_on='Search Term', right_on='searchterm', how='left')\n",
    "    filtered_with_trends['trend'] = filtered_with_trends['trend'].fillna('Unmapped')\n",
    "    \n",
    "    # indicator for unmapped/mapped search terms\n",
    "    filtered_with_trends['Unmapped/Mapped'] = filtered_with_trends['trend'].apply(lambda x: 'Unmapped' if x == 'Unmapped' else 'Mapped')\n",
    "    \n",
    "    # merge compared terms with trends\n",
    "    compared_trends = df_trends.rename(columns={'searchterm': 'Compared Term', 'trend': 'Compared Trend'})\n",
    "    filtered_with_trends = filtered_with_trends.merge(compared_trends, on='Compared Term', how='left', suffixes=('', '_compared'))\n",
    "    filtered_with_trends['Compared Trend'] = filtered_with_trends['Compared Trend'].fillna('Unmapped')\n",
    "    \n",
    "    # indicator for unmapped/mapped compared terms\n",
    "    filtered_with_trends['Compared Term Unmapped/Mapped'] = filtered_with_trends['Compared Trend'].apply(lambda x: 'Unmapped' if x == 'Unmapped' else 'Mapped')\n",
    "    filtered_with_trends['Final Trend'] = filtered_with_trends.apply(lambda x: x['trend'] if x['trend'] != 'Unmapped' else x['Compared Trend'], axis=1)\n",
    "    \n",
    "    # group by final trend\n",
    "    grouped_peripheral = filtered_with_trends.groupby(\"Final Trend\")\n",
    "    \n",
    "    results = []\n",
    "    for trend_group, group in grouped_peripheral:\n",
    "        group = group.reset_index(drop=True)\n",
    "        group = group.sort_values(by=\"Similarity Score\", ascending=False)\n",
    "        results.append(group)\n",
    "    \n",
    "    final_df = pd.concat(results).reset_index(drop=True)\n",
    "    \n",
    "    # filter for the specific trend\n",
    "    if trend in final_df['Final Trend'].values:\n",
    "        peripheral_df = final_df[final_df['Final Trend'] == trend]\n",
    "    else:\n",
    "        peripheral_df = pd.DataFrame(columns=[\"Search Term\", \"Compared Term\", \"Similarity Score\", \"Final Trend\", \"Unmapped/Mapped\", \"Compared Term Unmapped/Mapped\"])\n",
    "        print(f\"No peripheral words found for {trend}\")\n",
    "\n",
    "    peripheral_df['Similarity Score'] = peripheral_df['Similarity Score'].round(4)\n",
    "    # filter out words being compared to itself\n",
    "    df2 = peripheral_df[peripheral_df['Similarity Score'] < 1]\n",
    "\n",
    "    # csv file for all similarity scores results for the trend that fall within the threshold\n",
    "    peripheral_df.to_csv(f'{trend} Similarity Scores.csv', index=False)\n",
    "    \n",
    "    # get terms mapped to the trend\n",
    "    mapped_to_trend = peripheral_df[peripheral_df['Compared Trend'] == trend]['Compared Term'].unique()\n",
    "    # filter terms not mapped to the trend\n",
    "    df3 = df2[~df2['Compared Term'].isin(mapped_to_trend) & (df2['Compared Trend'] != 'Unmapped')]\n",
    "    \n",
    "    # csv file for compared terms not mapped to og trend\n",
    "    df3.to_csv(f'{trend} - Compared Terms Not Mapped to Original Trend.csv', index=False)\n",
    "    \n",
    "    # csv file for compared terms not mapped to any trend\n",
    "    df4 = peripheral_df[peripheral_df['Compared Term Unmapped/Mapped'] == 'Unmapped']\n",
    "    df4.to_csv(f'{trend} - Compared Terms Not Mapped to Any Trend.csv', index=False)\n",
    "\n",
    "    return peripheral_df, df3, df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa4667-de8a-4799-8523-0e3363b5005c",
   "metadata": {},
   "source": [
    "processes the 2 previous functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb5282d-6fb7-43ec-a7fe-7601193931d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_trend(trend, start_date, quantile=0.99):\n",
    "    melt, df_trends = preprocess_and_get_data(start_date)\n",
    "    peripheral_df, df3, df4 = process_trend_data(melt, df_trends, trend, quantile)\n",
    "    return melt, df_trends, peripheral_df, df3, df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de619f6-b2f3-4f25-937a-c16e44ff4978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e928e27f-f021-4152-9b63-ffbe48bd7db1",
   "metadata": {},
   "source": [
    "specify the trend you want to look at and the start date for that first initial query that pulls the search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f45b87a4-b732-4ff8-b767-e92bdb114a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 29s, sys: 35.7 s, total: 6min 5s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#example\n",
    "trend = \"Enemies to Lovers Romance\"\n",
    "melt, df_trends, peripheral_df, df3, df4 = process_trend(trend, start_date='2024-06-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b69c3b-ea24-487b-acb6-8f59dec041ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search Term</th>\n",
       "      <th>Compared Term</th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>searchterm</th>\n",
       "      <th>trend</th>\n",
       "      <th>Unmapped/Mapped</th>\n",
       "      <th>Compared Trend</th>\n",
       "      <th>Compared Term Unmapped/Mapped</th>\n",
       "      <th>Final Trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>1.0</td>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>Romcom Books</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>1.0</td>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>Romantic Comedy</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>1.0</td>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>All Romance</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>1.0</td>\n",
       "      <td>enemies to lovers romance</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>enemies to lovers romance books</td>\n",
       "      <td>enemies to lovers romance books</td>\n",
       "      <td>1.0</td>\n",
       "      <td>enemies to lovers romance books</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>Romcom Books</td>\n",
       "      <td>Mapped</td>\n",
       "      <td>Enemies to Lovers Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Search Term                    Compared Term  \\\n",
       "100001        enemies to lovers romance        enemies to lovers romance   \n",
       "100002        enemies to lovers romance        enemies to lovers romance   \n",
       "100003        enemies to lovers romance        enemies to lovers romance   \n",
       "100004        enemies to lovers romance        enemies to lovers romance   \n",
       "100005  enemies to lovers romance books  enemies to lovers romance books   \n",
       "\n",
       "        Similarity Score                       searchterm  \\\n",
       "100001               1.0        enemies to lovers romance   \n",
       "100002               1.0        enemies to lovers romance   \n",
       "100003               1.0        enemies to lovers romance   \n",
       "100004               1.0        enemies to lovers romance   \n",
       "100005               1.0  enemies to lovers romance books   \n",
       "\n",
       "                            trend Unmapped/Mapped             Compared Trend  \\\n",
       "100001  Enemies to Lovers Romance          Mapped               Romcom Books   \n",
       "100002  Enemies to Lovers Romance          Mapped            Romantic Comedy   \n",
       "100003  Enemies to Lovers Romance          Mapped                All Romance   \n",
       "100004  Enemies to Lovers Romance          Mapped  Enemies to Lovers Romance   \n",
       "100005  Enemies to Lovers Romance          Mapped               Romcom Books   \n",
       "\n",
       "       Compared Term Unmapped/Mapped                Final Trend  \n",
       "100001                        Mapped  Enemies to Lovers Romance  \n",
       "100002                        Mapped  Enemies to Lovers Romance  \n",
       "100003                        Mapped  Enemies to Lovers Romance  \n",
       "100004                        Mapped  Enemies to Lovers Romance  \n",
       "100005                        Mapped  Enemies to Lovers Romance  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(peripheral_df.shape)\n",
    "peripheral_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6291588f-9522-4ee0-8a9a-795b03783809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "# looking at the compared terms not mapped to the trend we're looking at\n",
    "print(df3['Compared Term'].nunique())\n",
    "# print(df3['Compared Term'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05745fe4-d350-42ff-a1ce-d4e0238f29af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enemies to lovers romance fantasy' 'enemies to lovers free books'\n",
      " 'enemies to lovers books spicy' 'enemies to lovers dark romance'\n",
      " 'enemies to lovers romance books' 'enemies to lovers romance']\n"
     ]
    }
   ],
   "source": [
    "# search terms that are alredy mapped to the trend\n",
    "print(df4['Search Term'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080d73cd-9ebd-4048-ae44-00b023980313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# unique unmapped terms\n",
    "print(df4['Compared Term'].nunique())\n",
    "# print(df4['Compared Term'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a75301d8-b9ab-4946-9fda-3631aae397ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search Term</th>\n",
       "      <th>Compared Term</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1 best seller</td>\n",
       "      <td>#1 best seller</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>#1 best seller</td>\n",
       "      <td>0.081819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00 free kindle books</td>\n",
       "      <td>#1 best seller</td>\n",
       "      <td>0.103107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00 free kindle books romance</td>\n",
       "      <td>#1 best seller</td>\n",
       "      <td>0.213628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.99</td>\n",
       "      <td>#1 best seller</td>\n",
       "      <td>0.138467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Search Term   Compared Term  Similarity Score\n",
       "0                  #1 best seller  #1 best seller          1.000000\n",
       "1                            0.00  #1 best seller          0.081819\n",
       "2          0.00 free kindle books  #1 best seller          0.103107\n",
       "3  0.00 free kindle books romance  #1 best seller          0.213628\n",
       "4                            0.99  #1 best seller          0.138467"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity matrix melted to long format\n",
    "melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5006311-4d02-4398-9470-6b11c28a36a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>searchterm</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiktok cookbook</td>\n",
       "      <td>Booktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book tok</td>\n",
       "      <td>Booktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>booktok books 2024</td>\n",
       "      <td>Booktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tiktok cookbook 2023</td>\n",
       "      <td>Booktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>booktok journal</td>\n",
       "      <td>Booktok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             searchterm    trend\n",
       "0       tiktok cookbook  Booktok\n",
       "1              book tok  Booktok\n",
       "2    booktok books 2024  Booktok\n",
       "3  tiktok cookbook 2023  Booktok\n",
       "4       booktok journal  Booktok"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trends table from `hc-data-prod-analytics.oss.bi_dashboard_trends_living_searchterms`\n",
    "df_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96957ced-a43a-43e9-be91-596a1f8c9ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m118"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
